{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKee6KntSKHM5+yrk8hWj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elifdonmez/disaster_tweet_analysis/blob/main/Disaster_Tweet_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries\n",
        "\n",
        "**Pandas:** It is used for data cleanup in the data frame <br>\n",
        "**Tranformers:** It has BertTokenizer BertForSequenceClassification and pipeline <br>\n",
        "**Torch:** Tensors and Dynamic neural networks in Python with GPU acceleration"
      ],
      "metadata": {
        "id": "FKLVxCCiLRZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers pandas torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX_iK0_ILTql",
        "outputId": "83412d69-4292-4659-b292-f38687059c39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Â Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "nAYKwXzxr_Oe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "file_path = 'tweets/DisasterTweets.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "LwlIsJ-D1tFz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Tokenization"
      ],
      "metadata": {
        "id": "NPtBfJQQsfrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Timestamp column to datetime\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "\n",
        "# Rename the columns to match the original script\n",
        "df.rename(columns={'Tweets': 'tweet', 'Timestamp': 'date'}, inplace=True)\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove retweets\n",
        "df = df[~df['tweet'].str.startswith('RT')]"
      ],
      "metadata": {
        "id": "VTfFUY1CsOiM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Hardcoded data\n",
        "\n",
        "*   Current date-time\n",
        "*   Current temperature\n",
        "\n",
        "Define keywords\n",
        "\n",
        "*   Help keywords\n",
        "*   Disaster keywords\n",
        "*  Cold keywords\n",
        "*  Hot keywords\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FsWlGKY3swu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define current date and weather conditions\n",
        "current_date = datetime(2024, 3, 4)  # Hardcoded for demonstration\n",
        "current_date = current_date.replace(tzinfo=None)\n",
        "current_temperature = 30  # Celsius degrees\n",
        "\n",
        "# Keywords for classification\n",
        "help_keywords = [\"help\", \"needed\", \"require\"]\n",
        "disaster_keywords = [\"drought\", \"flood\", \"wildfire\", \"hurricane\", \"disaster\", \"heatstroke\", \"earthquake\",\n",
        "                     \"tornadoe\", \"aftershock\", \"hazard\", \"safe\"]\n",
        "\n",
        "# Define keywords for cold and hot weather help requests\n",
        "cold_keywords = ['blanket', 'cold', 'freezing']\n",
        "hot_keywords = ['drinkable water', 'heatstroke']"
      ],
      "metadata": {
        "id": "SeTRJa3atw6k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preperation**"
      ],
      "metadata": {
        "id": "W_aZq-opudSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT model and tokenizer for sentiment analysis\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Sentiment analysis pipeline\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqa7DT3GuKL8",
        "outputId": "8823e68a-11a7-441f-b1d2-f5fbab286394"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "ITRbE2TkuV-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify tweet category\n",
        "def classify_category(tweet):\n",
        "    # Make all tweets lowercase\n",
        "    tweet_lower = tweet.lower()\n",
        "    # Check for help request keywords\n",
        "    if any(keyword in tweet_lower for keyword in help_keywords):\n",
        "        return \"Help Request\"\n",
        "\n",
        "    # Check for disaster status information keywords\n",
        "    if any(keyword in tweet_lower for keyword in disaster_keywords):\n",
        "        return \"Disaster Status Information\"\n",
        "\n",
        "    return \"Irrelevant\"\n",
        "\n",
        "\n",
        "# Apply classification function\n",
        "df['category'] = df['tweet'].apply(classify_category)\n",
        "\n",
        "# Filter relevant categories\n",
        "relevant_categories = [\"Help Request\", \"Disaster Status Information\"]\n",
        "df_relevant = df[df['category'].isin(relevant_categories)]"
      ],
      "metadata": {
        "id": "DIr2bu_ZuVi1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prioritization**"
      ],
      "metadata": {
        "id": "SMe0CjMQuxDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate priority based on time difference\n",
        "def calculate_priority_for_post_date(row):\n",
        "    date = row['date'].replace(tzinfo=None)\n",
        "    days_since_posted = (current_date - date).days\n",
        "\n",
        "    if days_since_posted > 5:\n",
        "        return \"High Priority\"\n",
        "    elif days_since_posted > 2:\n",
        "        return \"Medium Priority\"\n",
        "    else:\n",
        "        return \"Low Priority\"\n",
        "\n",
        "\n",
        "# Apply priority calculation\n",
        "df_relevant['priority'] = df_relevant.apply(calculate_priority_for_post_date, axis=1)\n",
        "\n",
        "\n",
        "#Â Increase the priority based on the weather information\n",
        "# of already prioritized tweets based on their post dates\n",
        "def increase_priority_for_wheather(row):\n",
        "    date_priority = row['priority']\n",
        "    tweet = row['tweet']\n",
        "\n",
        "    # If temperature is high, increase the priority of tweets that have hot keywords\n",
        "    if current_temperature > 15:\n",
        "        if date_priority == \"Medium Priority\" and any(keyword in tweet.lower() for keyword in hot_keywords):\n",
        "            return \"High Priority\"\n",
        "        elif date_priority == \"Low Priority\" and any(keyword in tweet.lower() for keyword in hot_keywords):\n",
        "            return \"Medium Priority\"\n",
        "        else:\n",
        "            return date_priority\n",
        "    # If temperature is low, increase the priority of tweets that have cold keywords\n",
        "    elif current_temperature < 15:\n",
        "        if date_priority == \"Medium Priority\" and any(keyword in tweet.lower() for keyword in cold_keywords):\n",
        "            return \"High Priority\"\n",
        "        elif date_priority == \"Low Priority\" and any(keyword in tweet.lower() for keyword in cold_keywords):\n",
        "            return \"Medium Priority\"\n",
        "        else:\n",
        "            return date_priority\n",
        "\n",
        "\n",
        "# Apply priority calculation\n",
        "df_relevant['priority'] = df_relevant.apply(increase_priority_for_wheather, axis=1)\n",
        "\n",
        "def decrease_priority_for_wheather(row):\n",
        "    priority = row['priority']\n",
        "    tweet = row['tweet']\n",
        "\n",
        "    # If temperature is high, decrease the priority of tweets that have cold keywords\n",
        "    if current_temperature > 15:\n",
        "        if priority == \"High Priority\" and any(keyword in tweet.lower() for keyword in cold_keywords):\n",
        "            return \"Medium Priority\"\n",
        "        elif priority == \"Medium Priority\" and any(keyword in tweet.lower() for keyword in cold_keywords):\n",
        "            return \"Low Priority\"\n",
        "        else:\n",
        "            return priority\n",
        "    # If temperature is low, decrease the priority of tweets that have hot keywords\n",
        "    elif current_temperature < 15:\n",
        "        if priority == \"High Priority\" and any(keyword in tweet.lower() for keyword in hot_keywords):\n",
        "            return \"Medium Priority\"\n",
        "        elif priority == \"Medium Priority\" and any(keyword in tweet.lower() for keyword in hot_keywords):\n",
        "            return \"Low Priority\"\n",
        "        else:\n",
        "            return priority\n",
        "\n",
        "# Apply priority calculation\n",
        "df_relevant['priority'] = df_relevant.apply(decrease_priority_for_wheather, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf_vOX2Au8AD",
        "outputId": "e396b6c5-0e90-4b12-e86b-1325a79432bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-d7c7a965e741>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_relevant['priority'] = df_relevant.apply(calculate_priority_for_post_date, axis=1)\n",
            "<ipython-input-8-d7c7a965e741>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_relevant['priority'] = df_relevant.apply(increase_priority_for_wheather, axis=1)\n",
            "<ipython-input-8-d7c7a965e741>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_relevant['priority'] = df_relevant.apply(decrease_priority_for_wheather, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis**\n",
        "\n",
        "Use Bert's sentiment analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "nJdwMgucvEII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get sentiment\n",
        "def get_sentiment(tweet):\n",
        "    result = sentiment_analysis(tweet)\n",
        "    star_rating = int(result[0]['label'].split()[0])\n",
        "\n",
        "    if star_rating == 1:\n",
        "        return \"Very Negative\"\n",
        "    elif star_rating == 2:\n",
        "        return \"Negative\"\n",
        "    elif star_rating == 3:\n",
        "        return \"Neutral\"\n",
        "    elif star_rating == 4:\n",
        "        return \"Positive\"\n",
        "    elif star_rating == 5:\n",
        "        return \"Very Positive\"\n",
        "\n",
        "\n",
        "# Apply sentiment analysis to relevant tweets\n",
        "df_relevant['sentiment'] = df_relevant['tweet'].apply(get_sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX7uhzSEvIWs",
        "outputId": "6ffbd603-954c-4d55-9110-903e0bc8bb0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-6bd5f5632b37>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_relevant['sentiment'] = df_relevant['tweet'].apply(get_sentiment)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Display Results**"
      ],
      "metadata": {
        "id": "HG-gir4IvNpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the desired columns\n",
        "df_result = df_relevant[['date', 'tweet', 'category', 'priority', 'sentiment']]\n",
        "df_result = df_result.merge(df[['date', 'Verified', 'Disaster']], on='date', how='left')\n",
        "\n",
        "# Write the result to a new CSV file\n",
        "output_file_path = 'tweets/DisasterTweets_Analyzed.csv'\n",
        "df_result.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f'Results have been saved to {output_file_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T409OEC98HyI",
        "outputId": "8815e034-46cc-46ba-bb02-a4d12e8680c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results have been saved to tweets/DisasterTweets_Analyzed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the cleaned, filtered, and analyzed DataFrame\n",
        "print(df_relevant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U7iI_T6vMay",
        "outputId": "7f2af18f-2b93-46c0-eef0-5f4396194c6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Name          UserName  \\\n",
            "0                                 Drought Center    @DroughtCenter   \n",
            "1                       Prabhakar Goud Kurmimdla  @PrabhakarGoud_K   \n",
            "2                   Humanity First International          @HFI1995   \n",
            "3     NCWQ Worldwide News And Disasters Explorer    @RTheExplorer1   \n",
            "4                                  BestDealsEver  @MilwaukeeHotBuy   \n",
            "...                                          ...               ...   \n",
            "2553                                        JYHK         @JYHKeung   \n",
            "2554                            Mark R. Sheridan  @DisasterLessons   \n",
            "2556                           Earthquake Alerts      @QuakesToday   \n",
            "2557                     Trader PhD Ag Marketing        @TraderPhD   \n",
            "2558                             Giuseppe Forino     @G_leipheimer   \n",
            "\n",
            "                          date  Verified  \\\n",
            "0    2024-02-29 13:30:07+00:00     False   \n",
            "1    2024-02-27 05:20:43+00:00     False   \n",
            "2    2024-03-03 07:03:34+00:00     False   \n",
            "3    2024-02-29 10:20:18+00:00     False   \n",
            "4    2024-02-28 17:58:01+00:00     False   \n",
            "...                        ...       ...   \n",
            "2553 2024-02-29 18:11:46+00:00     False   \n",
            "2554 2024-02-24 16:55:00+00:00     False   \n",
            "2556 2024-03-04 09:11:04+00:00     False   \n",
            "2557 2024-02-29 16:44:16+00:00     False   \n",
            "2558 2024-02-28 11:47:51+00:00     False   \n",
            "\n",
            "                                                  tweet  Comments  Retweets  \\\n",
            "0     US Drought Monitor 2-29-24\\n\\nHappy Leap Day! ...         0        17   \n",
            "1                                   Synonym is #Drought         0         0   \n",
            "2     Across South America in the last two months, #...         0         9   \n",
            "3     Wildfires  Going On In Texas  #wildfires #texa...         0         0   \n",
            "4     START YOUR STAND UP COMEDY CAREER FOR $11.99  ...         0         0   \n",
            "...                                                 ...       ...       ...   \n",
            "2553  #politicians and big #companies such as #3M #i...         0         0   \n",
            "2554  See Feb 23 2024  Story: Extreme Weather Is Com...         0         1   \n",
            "2556  1.7 magnitude #earthquake. 24 km from Coalinga...         0         1   \n",
            "2557  The contiguous U.S. saw high #temperatures dur...         0         0   \n",
            "2558  #Memory of #floods in green public space, on t...         0         0   \n",
            "\n",
            "     Likes  Impressions                                               Tags  \\\n",
            "0       13        18000  ['#droughtmonitor', '#drought', '#drought2024'...   \n",
            "1        1           13                                       ['#Drought']   \n",
            "2       19          419  ['#floods', '#landslides', '#drought', '#wildf...   \n",
            "3        1           34                      ['#wildfires', '#texasfires']   \n",
            "4        0          210  ['#thevoice', '#rhonj', '#taylorswift', '#mia'...   \n",
            "...    ...          ...                                                ...   \n",
            "2553     0           15  ['#politicians', '#companies', '#3M', '#ineos'...   \n",
            "2554     0           61  ['#Prepare', '#Flooding', '#Hurricanes', '#Tor...   \n",
            "2556     1          584                             ['#earthquake', '#CA']   \n",
            "2557     1          185                      ['#temperatures', '#Drought']   \n",
            "2558     0           96                             ['#Memory', '#floods']   \n",
            "\n",
            "                                             Tweet Link      Tweet ID  \\\n",
            "0     https://twitter.com/DroughtCenter/status/17631...  1.763190e+18   \n",
            "1     https://twitter.com/PrabhakarGoud_K/status/176...  1.762350e+18   \n",
            "2     https://twitter.com/HFI1995/status/17641848294...  1.764180e+18   \n",
            "3     https://twitter.com/RTheExplorer1/status/17631...  1.763150e+18   \n",
            "4     https://twitter.com/MilwaukeeHotBuy/status/176...  1.762900e+18   \n",
            "...                                                 ...           ...   \n",
            "2553  https://twitter.com/JYHKeung/status/1763265821...  1.763270e+18   \n",
            "2554  https://twitter.com/DisasterLessons/status/176...  1.761430e+18   \n",
            "2556  https://twitter.com/QuakesToday/status/1764579...  1.764580e+18   \n",
            "2557  https://twitter.com/TraderPhD/status/176324380...  1.763240e+18   \n",
            "2558  https://twitter.com/G_leipheimer/status/176280...  1.762810e+18   \n",
            "\n",
            "        Disaster                     category         priority      sentiment  \n",
            "0        Drought  Disaster Status Information  Medium Priority       Positive  \n",
            "1        Drought  Disaster Status Information  Medium Priority        Neutral  \n",
            "2         Floods  Disaster Status Information     Low Priority  Very Negative  \n",
            "3       Wildfire  Disaster Status Information  Medium Priority  Very Positive  \n",
            "4     Hurricanes  Disaster Status Information  Medium Priority  Very Positive  \n",
            "...          ...                          ...              ...            ...  \n",
            "2553      Floods  Disaster Status Information  Medium Priority  Very Positive  \n",
            "2554   Tornadoes  Disaster Status Information    High Priority  Very Negative  \n",
            "2556  Earthquake  Disaster Status Information     Low Priority  Very Negative  \n",
            "2557     Drought  Disaster Status Information  Medium Priority       Negative  \n",
            "2558      Floods  Disaster Status Information  Medium Priority  Very Positive  \n",
            "\n",
            "[2373 rows x 16 columns]\n"
          ]
        }
      ]
    }
  ]
}